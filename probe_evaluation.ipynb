{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens.utils as utils\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "import einops\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from fancy_einsum import einsum\n",
    "import chess\n",
    "import numpy as np\n",
    "import csv\n",
    "from dataclasses import dataclass\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import logging\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import chess_utils\n",
    "import train_test_chess\n",
    "from train_test_chess import Config, LinearProbeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags to control logging\n",
    "debug_mode = False\n",
    "info_mode = True\n",
    "\n",
    "if debug_mode:\n",
    "    log_level = logging.DEBUG\n",
    "elif info_mode:\n",
    "    log_level = logging.INFO\n",
    "else:\n",
    "    log_level = logging.WARNING\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=log_level)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"models/\"\n",
    "DATA_DIR = \"data/\"\n",
    "PROBE_DIR = \"linear_probes/\"\n",
    "SAVED_PROBE_DIR = \"linear_probes/saved_probes/\"\n",
    "SPLIT = \"test\"\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "probe_to_test = \"tf_lens_lichess_16layers_ckpt_no_optimizer_chess_piece_probe_layer_12_pos_start_0.pth\"\n",
    "\n",
    "probe_file_location = f\"{SAVED_PROBE_DIR}{probe_to_test}\"\n",
    "with open(probe_file_location, \"rb\") as f:\n",
    "    state_dict = torch.load(f, map_location=torch.device(device))\n",
    "    print(state_dict.keys())\n",
    "    for key in state_dict.keys():\n",
    "        if key != \"linear_probe\":\n",
    "            print(key, state_dict[key])\n",
    "\n",
    "    config = train_test_chess.find_config_by_name(state_dict[\"config_name\"])\n",
    "    layer = state_dict[\"layer\"]\n",
    "    model_name = state_dict[\"model_name\"]\n",
    "    dataset_prefix = state_dict[\"dataset_prefix\"]\n",
    "    process_data = state_dict[\"process_data\"]\n",
    "    column_name = state_dict[\"column_name\"]\n",
    "    config.pos_start = state_dict[\"pos_start\"]\n",
    "    levels_of_interest = None\n",
    "    if \"levels_of_interest\" in state_dict.keys():\n",
    "        levels_of_interest = state_dict[\"levels_of_interest\"]\n",
    "    config.levels_of_interest = levels_of_interest\n",
    "    indexing_function_name = state_dict[\"indexing_function_name\"]\n",
    "    n_layers = state_dict[\"n_layers\"]\n",
    "\n",
    "    split = SPLIT\n",
    "    input_dataframe_file = f\"{DATA_DIR}{dataset_prefix}{split}.csv\"\n",
    "    config = train_test_chess.set_config_min_max_vals_and_column_name(\n",
    "        config, input_dataframe_file, dataset_prefix\n",
    "    )\n",
    "    misc_logging_dict = {\n",
    "        \"split\": split,\n",
    "        \"dataset_prefix\": dataset_prefix,\n",
    "        \"model_name\": model_name,\n",
    "        \"n_layers\": n_layers,\n",
    "    }\n",
    "\n",
    "    probe_data = train_test_chess.construct_linear_probe_data(\n",
    "        input_dataframe_file,\n",
    "        layer,\n",
    "        dataset_prefix,\n",
    "        split,\n",
    "        n_layers,\n",
    "        model_name,\n",
    "        config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1\n",
    "modes = 1\n",
    "\n",
    "game_length_in_chars = len(probe_data.board_seqs_string[0])\n",
    "\n",
    "\n",
    "state_stacks_all_chars = chess_utils.create_state_stacks(probe_data.board_seqs_string[:sample_size], config.custom_board_state_function)\n",
    "logger.info(f\"state_stack shape: {state_stacks_all_chars.shape}\")\n",
    "assert(state_stacks_all_chars.shape) == (modes, sample_size, game_length_in_chars, config.num_rows, config.num_cols)\n",
    "white_move_indices = probe_data.custom_indices[:sample_size]\n",
    "print(white_move_indices.shape)\n",
    "num_white_moves = white_move_indices.shape[1]\n",
    "assert(white_move_indices.shape) == (sample_size, num_white_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_of_interest = 12\n",
    "move_of_interest_index = white_move_indices[0][move_of_interest]\n",
    "move_of_interest_state = state_stacks_all_chars[0][0][move_of_interest_index]\n",
    "print(move_of_interest_state.shape)\n",
    "print(move_of_interest_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(probe_file_location, map_location=torch.device(device))\n",
    "linear_probe = checkpoint[\"linear_probe\"]\n",
    "print(linear_probe.shape)\n",
    "\n",
    "# for piece type one hot vectors\n",
    "min_val = -6\n",
    "max_val = 6\n",
    "\n",
    "\n",
    "one_hot_range = config.max_val - config.min_val + 1\n",
    "\n",
    "games_int = probe_data.board_seqs_int[:sample_size]\n",
    "games_dots = white_move_indices[:sample_size]\n",
    "\n",
    "indexed_state_stacks = []\n",
    "\n",
    "for batch_idx in range(state_stacks_all_chars.size(0)):\n",
    "    # Get the indices for the current batch\n",
    "    dots_indices_for_batch = games_dots[batch_idx]\n",
    "\n",
    "    # Index the state_stack for the current batch\n",
    "    indexed_state_stack = state_stacks_all_chars[:,batch_idx, dots_indices_for_batch, :, :]\n",
    "\n",
    "    # Append the result to the list\n",
    "    indexed_state_stacks.append(indexed_state_stack)\n",
    "\n",
    "# Stack the indexed state stacks along the first dimension\n",
    "state_stack_white_moves = torch.stack(indexed_state_stacks)\n",
    "# print(\"after indexing state stack shape\", state_stack.shape)\n",
    "print(\"state stack shapes\")\n",
    "print(state_stack_white_moves.shape)\n",
    "print(state_stacks_all_chars.shape)\n",
    "\n",
    "state_stack_one_hot = chess_utils.state_stack_to_one_hot(modes,\n",
    "                                 config.num_rows, config.num_cols, config.min_val, config.max_val, device, state_stack_white_moves).to(device)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    _, cache = probe_data.model.run_with_cache(games_int.to(device)[:, :-1], return_type=None)\n",
    "    resid_post = cache[\"resid_post\", layer][:, :]\n",
    "\n",
    "print(resid_post.shape)\n",
    "\n",
    "# Initialize a list to hold the indexed state stacks\n",
    "indexed_resid_posts = []\n",
    "\n",
    "for batch_idx in range(games_dots.size(0)):\n",
    "    # Get the indices for the current batch\n",
    "    dots_indices_for_batch = games_dots[batch_idx]\n",
    "\n",
    "    # Index the state_stack for the current batch\n",
    "    indexed_resid_post = resid_post[batch_idx, dots_indices_for_batch]\n",
    "\n",
    "    # Append the result to the list\n",
    "    indexed_resid_posts.append(indexed_resid_post)\n",
    "\n",
    "# Stack the indexed state stacks along the first dimension\n",
    "# This results in a tensor of shape [2, 61, 8, 8] (assuming all batches have 61 indices)\n",
    "resid_post = torch.stack(indexed_resid_posts)\n",
    "resid_post = resid_post.to(device)\n",
    "# print(\"Resid post\", resid_post.shape)\n",
    "probe_out = einsum(\n",
    "    \"batch pos d_model, modes d_model rows cols options -> modes batch pos rows cols options\",\n",
    "    resid_post,\n",
    "    linear_probe,\n",
    ")\n",
    "print(probe_out.shape)\n",
    "assert(probe_out.shape) == (state_stack_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_stacks_one_hot = chess_utils.state_stack_to_one_hot(modes, config.num_rows, config.num_cols, config.min_val, config.max_val, device, state_stacks_all_chars)\n",
    "print(state_stacks_one_hot.shape)\n",
    "assert(state_stacks_one_hot.shape) == (modes, sample_size, game_length_in_chars, config.num_rows, config.num_cols, one_hot_range)\n",
    "move_of_interest_state_one_hot = state_stacks_one_hot[0][0][move_of_interest_index]\n",
    "print(move_of_interest_state_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(move_of_interest_state_one_hot.shape)\n",
    "print(state_stacks_one_hot.shape)\n",
    "print(probe_out.shape)\n",
    "assert(probe_out.shape) == (modes, sample_size, num_white_moves, config.num_rows, config.num_cols, one_hot_range)\n",
    "state_stacks_probe_outputs = chess_utils.one_hot_to_state_stack(probe_out, config.min_val)\n",
    "state_stacks_probe_outputs = torch.tensor(state_stacks_probe_outputs)\n",
    "print(state_stacks_probe_outputs.shape)\n",
    "assert(state_stacks_probe_outputs.shape) == (modes, sample_size, num_white_moves, config.num_rows, config.num_cols)\n",
    "print(state_stacks_probe_outputs[0][0][move_of_interest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of chess pieces to integers\n",
    "PIECE_TO_INT = {\n",
    "    chess.PAWN: 1,\n",
    "    chess.KNIGHT: 2,\n",
    "    chess.BISHOP: 3,\n",
    "    chess.ROOK: 4,\n",
    "    chess.QUEEN: 5,\n",
    "    chess.KING: 6,\n",
    "}\n",
    "\n",
    "INT_TO_CHAR = {\n",
    "    -6: \"k\",\n",
    "    -5: \"q\",\n",
    "    -4: \"r\",\n",
    "    -3: \"b\",\n",
    "    -2: \"n\",\n",
    "    -1: \"p\",\n",
    "    0: \".\",\n",
    "    1: \"P\",\n",
    "    2: \"N\",\n",
    "    3: \"B\",\n",
    "    4: \"R\",\n",
    "    5: \"Q\",\n",
    "    6: \"K\",\n",
    "}\n",
    "\n",
    "# Mapping of integers to chess pieces\n",
    "PIECE_TO_ONE_HOT_MAPPING = {-6: 0, -5: 1, -4: 2, -3: 3, -2: 4, -1: 5, 0: 6, 1: 7, 2: 8, 3: 9, 4: 10, 5: 11, 6: 12}\n",
    "\n",
    "blank_index = PIECE_TO_ONE_HOT_MAPPING[0]\n",
    "white_pawn_index = PIECE_TO_ONE_HOT_MAPPING[1]\n",
    "black_king_index = PIECE_TO_ONE_HOT_MAPPING[-6]\n",
    "\n",
    "def plot_board_state(board_state: torch.Tensor, clip_size: int = 200):\n",
    "    # color scale: Black for -1, Gray for 0, White for 1\n",
    "    # colorscale = [[0.0, 'black'], [0.5, 'gray'], [1.0, 'white']]\n",
    "    colorscale = 'gray'\n",
    "    board_state = np.clip(board_state.numpy(), -clip_size, clip_size)\n",
    "\n",
    "    # Create heatmap\n",
    "    heatmap = go.Heatmap(z=board_state, colorscale=colorscale)\n",
    "    return heatmap\n",
    "\n",
    "heatmap = plot_board_state(move_of_interest_state_one_hot[:, :, white_pawn_index])\n",
    "\n",
    "# Define the layout\n",
    "layout = go.Layout(\n",
    "    title=\"Chess board white pawns\",\n",
    "    xaxis=dict(ticks='', nticks=8),\n",
    "    yaxis=dict(ticks='', nticks=8),\n",
    "    autosize=False,\n",
    "    width=600,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# Create figure and plot\n",
    "fig = go.Figure(data=[heatmap], layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_text(board_state: torch.Tensor) -> np.ndarray:\n",
    "    # Create a mapping from numbers to characters\n",
    "    # Update this mapping according to your requirements\n",
    "\n",
    "    # Convert the tensor to numpy array for easier processing\n",
    "    board_array = board_state.numpy()\n",
    "\n",
    "    # Create an empty array with the same shape for text\n",
    "    text_array = np.empty(board_array.shape, dtype=str)\n",
    "\n",
    "    # Fill the text array with corresponding characters\n",
    "    for i in range(board_array.shape[0]):\n",
    "        for j in range(board_array.shape[1]):\n",
    "            text_array[i, j] = INT_TO_CHAR.get(board_array[i, j], str(board_array[i, j]))\n",
    "\n",
    "    return text_array\n",
    "\n",
    "def plot_board_state_with_text(board_state: torch.Tensor):\n",
    "    # Convert the tensor to a text matrix\n",
    "    text_matrix = tensor_to_text(board_state)\n",
    "\n",
    "    # Define the custom colorscale\n",
    "    colorscale = [\n",
    "        [0, 'black'],   # Negative values\n",
    "        [0.49, 'black'],\n",
    "        [0.5, 'grey'],  # Zero\n",
    "        [0.51, 'white'],\n",
    "        [1, 'white']    # Positive values\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Create heatmap with text and custom colorscale\n",
    "    heatmap = go.Heatmap(\n",
    "        z=board_state.numpy(), \n",
    "        text=text_matrix, \n",
    "        showscale=False, \n",
    "        colorscale=colorscale,\n",
    "        texttemplate=\"%{text}\"  # Set the texttemplate here\n",
    "    )\n",
    "\n",
    "    return heatmap\n",
    "heatmap = plot_board_state_with_text(move_of_interest_state)\n",
    "\n",
    "# Define the layout\n",
    "layout = go.Layout(\n",
    "    title=\"Chess board state with text\",\n",
    "    xaxis=dict(ticks='', nticks=8),\n",
    "    yaxis=dict(ticks='', nticks=8),\n",
    "    autosize=False,\n",
    "    width=600,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# Create figure and plot\n",
    "fig = go.Figure(data=[heatmap], layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "move_of_interest_probe_out = probe_out[0][0][move_of_interest]\n",
    "print(move_of_interest_probe_out.shape)\n",
    "\n",
    "fig_rows = 4\n",
    "fig_cols = 3\n",
    "fig = make_subplots(rows=fig_rows, cols=fig_cols, subplot_titles=[\n",
    "    \"Chess board blank squares\", \"Probe output blank squares clip=2\", \"Probe output blank squares no clipping\",\n",
    "    \"Chess board white pawns\", \"Probe output white pawns clip=5\", \"Probe output white pawns no clipping\",\n",
    "    \"Chess board black king\", \"Probe output black king clip=5\", \"Probe output black king no clipping\",\n",
    "    \"Chess board state\", \"Probe output board state\", \"Redundant probe output board state\"\n",
    "])\n",
    "\n",
    "\n",
    "# Specify the size of each plot\n",
    "plot_size = 400  # You can adjust this size\n",
    "\n",
    "fig.add_trace(plot_board_state(move_of_interest_state_one_hot[:, :, blank_index]), row=1, col=1)\n",
    "fig.add_trace(plot_board_state(move_of_interest_probe_out[:, :, blank_index], clip_size=2), row=1, col=2)\n",
    "fig.add_trace(plot_board_state(move_of_interest_probe_out[:, :, blank_index]), row=1, col=3)\n",
    "\n",
    "fig.add_trace(plot_board_state(move_of_interest_state_one_hot[:, :, white_pawn_index]), row=2, col=1)\n",
    "fig.add_trace(plot_board_state(move_of_interest_probe_out[:, :, white_pawn_index], clip_size=5), row=2, col=2)\n",
    "fig.add_trace(plot_board_state(move_of_interest_probe_out[:, :, white_pawn_index]), row=2, col=3)\n",
    "\n",
    "fig.add_trace(plot_board_state(move_of_interest_state_one_hot[:, :, black_king_index]), row=3, col=1)\n",
    "fig.add_trace(plot_board_state(move_of_interest_probe_out[:, :, black_king_index], clip_size=5), row=3, col=2)\n",
    "fig.add_trace(plot_board_state(move_of_interest_probe_out[:, :, black_king_index]), row=3, col=3)\n",
    "\n",
    "fig.add_trace(plot_board_state_with_text(move_of_interest_state), row=4, col=1)\n",
    "fig.add_trace(plot_board_state_with_text(state_stacks_probe_outputs[0][0][move_of_interest]), row=4, col=2)\n",
    "fig.add_trace(plot_board_state_with_text(state_stacks_probe_outputs[0][0][move_of_interest]), row=4, col=2)\n",
    "\n",
    "# Adjust the overall size of the figure\n",
    "fig.update_layout(height=fig_rows * plot_size, width=fig_cols * plot_size)\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_matching_percentage(state_stacks: torch.Tensor, probe_outputs: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the percentage of matching cells in two tensors.\n",
    "\n",
    "    :param state_stacks: A tensor of shape [1, 1, 680, 8, 8].\n",
    "    :param probe_outputs: A tensor of shape [1, 1, 680, 8, 8].\n",
    "    :return: The percentage of cells that match.\n",
    "    \"\"\"\n",
    "    # Element-wise comparison\n",
    "    matches = state_stacks == probe_outputs\n",
    "\n",
    "    # Count the number of matches\n",
    "    num_matches = matches.sum().item()\n",
    "\n",
    "    # Total number of elements\n",
    "    total_elements = state_stacks.numel()\n",
    "\n",
    "    # Calculate percentage\n",
    "    percentage = (num_matches / total_elements) * 100\n",
    "    print(f\"Out of {total_elements} elements, {num_matches} matched, {percentage}%\")\n",
    "\n",
    "    return percentage\n",
    "assert(state_stacks_probe_outputs.shape) == (state_stack_white_moves.shape)\n",
    "print(\"Linear probe accuracy on all board squares in sample size:\", calculate_matching_percentage(state_stack_white_moves, state_stacks_probe_outputs))\n",
    "\n",
    "round_trip = chess_utils.one_hot_to_state_stack(chess_utils.state_stack_to_one_hot(modes, config.num_rows, config.num_cols, config.min_val,config.max_val, device, state_stack_white_moves), config.min_val)\n",
    "round_trip = torch.tensor(round_trip)\n",
    "print(round_trip.shape)\n",
    "print(state_stack_white_moves.shape)\n",
    "assert(round_trip.shape) == (modes, sample_size, num_white_moves, config.num_rows, config.num_cols)\n",
    "assert(round_trip.shape) == state_stack_white_moves.shape\n",
    "matching_percentage = calculate_matching_percentage(round_trip, state_stack_white_moves)\n",
    "assert(matching_percentage == 100.0)\n",
    "print(f\"Round trip matching percentage: {matching_percentage}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
