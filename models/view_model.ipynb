{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = 'checkpointBeta.pth'\n",
    "karvmodel = 'lichess_8layers_ckpt_no_optimizer.pt' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'optimizer', 'model_args', 'iter_num', 'best_val_loss', 'config'])\n",
      "model_args {'n_layer': 8, 'n_head': 8, 'n_embd': 512, 'block_size': 1023, 'bias': False, 'vocab_size': 32, 'dropout': 0.0}\n",
      "iter_num 20000\n",
      "best_val_loss tensor(0.5684)\n",
      "config {'out_dir': 'chess_saver', 'eval_interval': 1000, 'log_interval': 100, 'eval_iters': 100, 'eval_only': False, 'always_save_checkpoint': False, 'init_from': 'resume', 'wandb_log': True, 'mlflow_log': True, 'mlflow_location': 'mlflow_storage', 'wandb_project': 'chess-gpt-batch', 'wandb_run_name': '8layer_lichess', 'dataset': 'lichess_hf_dataset', 'gradient_accumulation_steps': 4, 'batch_size': 120, 'block_size': 1023, 'n_layer': 8, 'n_head': 8, 'n_embd': 512, 'dropout': 0.0, 'bias': False, 'learning_rate': 0.0003, 'max_iters': 600000, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'decay_lr': True, 'warmup_iters': 2000, 'lr_decay_iters': 600000, 'min_lr': 3e-05, 'backend': 'nccl', 'data_type': '5M', 'device': 'cuda', 'dtype': 'bfloat16', 'compile': True}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with open(mymodel, 'rb') as f:\n",
    "    state_dict = torch.load(f, map_location=torch.device('cpu'))\n",
    "    print(state_dict.keys())\n",
    "    for key in state_dict.keys():\n",
    "        if key != \"model\" and key != \"optimizer\":\n",
    "            print(key, state_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'model_args', 'iter_num', 'best_val_loss', 'config', 'dataset'])\n",
      "model_args {'n_layer': 8, 'n_head': 8, 'n_embd': 512, 'block_size': 1023, 'bias': False, 'vocab_size': 32, 'dropout': 0.0}\n",
      "iter_num 600000\n",
      "best_val_loss tensor(0.2166)\n",
      "config {'out_dir': 'out-shakespeare-char', 'eval_interval': 4000, 'log_interval': 100, 'eval_iters': 100, 'eval_only': False, 'always_save_checkpoint': True, 'init_from': 'scratch', 'wandb_log': True, 'wandb_project': 'chess-gpt-batch', 'wandb_run_name': 'lichess_all_elos_8layers', 'dataset': 'lichess_hf_dataset', 'gradient_accumulation_steps': 1, 'batch_size': 100, 'block_size': 1023, 'n_layer': 8, 'n_head': 8, 'n_embd': 512, 'dropout': 0.0, 'bias': False, 'learning_rate': 0.0003, 'max_iters': 600000.0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'decay_lr': True, 'warmup_iters': 1000, 'lr_decay_iters': 600000.0, 'min_lr': 3e-05, 'backend': 'nccl', 'device': 'cuda', 'dtype': 'bfloat16', 'compile': True}\n",
      "dataset lichess_6gb_blocks.zip\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with open(karvmodel, 'rb') as f:\n",
    "    state_dict = torch.load(f, map_location=torch.device('cpu'))\n",
    "    print(state_dict.keys())\n",
    "    for key in state_dict.keys():\n",
    "        if key != \"model\" and key != \"optimizer\":\n",
    "            print(key, state_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 32, 'itos': {0: ' ', 1: '#', 2: '+', 3: '-', 4: '.', 5: '0', 6: '1', 7: '2', 8: '3', 9: '4', 10: '5', 11: '6', 12: '7', 13: '8', 14: '9', 15: ';', 16: '=', 17: 'B', 18: 'K', 19: 'N', 20: 'O', 21: 'Q', 22: 'R', 23: 'a', 24: 'b', 25: 'c', 26: 'd', 27: 'e', 28: 'f', 29: 'g', 30: 'h', 31: 'x'}, 'stoi': {' ': 0, '#': 1, '+': 2, '-': 3, '.': 4, '0': 5, '1': 6, '2': 7, '3': 8, '4': 9, '5': 10, '6': 11, '7': 12, '8': 13, '9': 14, ';': 15, '=': 16, 'B': 17, 'K': 18, 'N': 19, 'O': 20, 'Q': 21, 'R': 22, 'a': 23, 'b': 24, 'c': 25, 'd': 26, 'e': 27, 'f': 28, 'g': 29, 'h': 30, 'x': 31}}\n",
      "[6, 4, 27, 9, 0, 27, 11, 0, 7, 4, 19, 28, 8, 0, 26, 10, 0, 8, 4, 19, 25, 8, 0, 26, 9, 0, 9, 4, 19, 27, 7, 0, 25, 10, 0, 10, 4, 25, 8, 0, 26, 8, 0, 11, 4, 19, 28, 9, 0, 25, 9, 0, 12, 4, 21, 23, 9, 2, 0, 17, 26, 12, 0, 13, 4, 21, 31, 25, 9, 0, 19, 28, 11, 0, 14, 4, 27, 10, 0, 19, 29, 9, 0, 6, 5, 4, 30, 8, 0, 19, 31, 28, 7, 0, 6, 6, 4, 18, 31, 28, 7, 0, 21, 24, 11, 2, 0, 6, 7, 4, 18, 27, 6, 0, 17, 24, 10, 0, 6, 8, 4, 21, 25, 13, 2, 0, 18, 27, 12, 0, 6, 9, 4, 17, 31, 26, 8, 0, 17, 26, 12, 0, 6, 10, 4, 21, 25, 9, 0, 19, 25, 11, 0, 6, 11, 4, 17, 27, 9, 0, 22, 25, 13, 0, 6, 12, 4, 21, 24, 8, 0, 21, 25, 12, 0, 6, 13, 4, 26, 9, 0, 22, 24, 13, 0, 6, 14, 4, 17, 27, 8, 0, 19, 23, 10, 0, 7, 5, 4, 21, 26, 6, 0, 29, 11, 0, 7, 6, 4, 17, 26, 8, 0, 17, 29, 12, 0, 7, 7, 4, 22, 28, 6, 0, 19, 25, 11, 0, 7, 8, 4, 18, 28, 7, 0, 22, 30, 27, 13, 0, 7, 9, 4, 18, 29, 6, 0, 30, 11, 0, 7, 10, 4, 22, 25, 6, 0, 29, 10, 0, 7, 11, 4, 19, 30, 10, 0, 17, 30, 13, 0, 7, 12, 4, 19, 26, 7, 0, 21, 24, 11, 0, 7, 13, 4, 19, 28, 11, 0, 22, 27, 26, 13, 0, 7, 14, 4, 19, 31, 26, 12, 0, 22, 31, 26, 12, 0, 8, 5, 4, 21, 28, 8, 0, 21, 31, 24, 7, 0, 8, 6, 4, 21, 31, 28, 12, 2, 0, 18, 26, 13, 0, 8, 7, 4, 21, 28, 13, 2]\n",
      ";1.e4 \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# meta is used to encode the string pgn strings into integer sequences\n",
    "with open(\"meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "\n",
    "print(meta)\n",
    "\n",
    "stoi, itos = meta[\"stoi\"], meta[\"itos\"]\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: \"\".join([itos[i] for i in l])\n",
    "\n",
    "print(encode(\"1.e4 e6 2.Nf3 d5 3.Nc3 d4 4.Ne2 c5 5.c3 d3 6.Nf4 c4 7.Qa4+ Bd7 8.Qxc4 Nf6 9.e5 Ng4 10.h3 Nxf2 11.Kxf2 Qb6+ 12.Ke1 Bb5 13.Qc8+ Ke7 14.Bxd3 Bd7 15.Qc4 Nc6 16.Be4 Rc8 17.Qb3 Qc7 18.d4 Rb8 19.Be3 Na5 20.Qd1 g6 21.Bd3 Bg7 22.Rf1 Nc6 23.Kf2 Rhe8 24.Kg1 h6 25.Rc1 g5 26.Nh5 Bh8 27.Nd2 Qb6 28.Nf6 Red8 29.Nxd7 Rxd7 30.Qf3 Qxb2 31.Qxf7+ Kd8 32.Qf8+\"))\n",
    "print(decode(encode(\";1.e4 \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells can be used to modify a checkpoint, such as by removing the optimizer or adding dataset metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'model_args', 'iter_num', 'best_val_loss', 'config', 'dataset'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "checkpoint = torch.load(karvmodel, map_location='cpu')\n",
    "print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'optimizer', 'model_args', 'iter_num', 'best_val_loss', 'config'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "checkpoint = torch.load(mymodel, map_location='cpu')\n",
    "print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add the new key-value pair to the checkpoint\n",
    "checkpoint[\"dataset\"] = \"lichess_6gb_results_blocks.zip\"\n",
    "\n",
    "# Save the modified checkpoint\n",
    "torch.save(checkpoint, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(model_name, map_location='cpu')\n",
    "print(state_dict.keys())\n",
    "\n",
    "del state_dict['optimizer']\n",
    "print(state_dict.keys())\n",
    "\n",
    "new_model_name = model_name.replace('with_optimizer.pt', 'no_optimizer.pt')\n",
    "torch.save(state_dict, new_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoint['dataset'])\n",
    "print(checkpoint['best_val_loss'])\n",
    "print(checkpoint['iter_num'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
