{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens.utils as utils\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "# from mech_interp_othello_utils import OthelloBoardState\n",
    "import einops\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from fancy_einsum import einsum\n",
    "import chess\n",
    "import numpy as np\n",
    "import csv\n",
    "import chess_utils\n",
    "from dataclasses import dataclass\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "\n",
    "device = \"cuda\"\n",
    "device = \"cpu\"\n",
    "device = \"mps\"\n",
    "\n",
    "n_layers = 16\n",
    "n_heads = 8\n",
    "MODEL_DIR = \"models/\"\n",
    "DATA_DIR = \"data/\"\n",
    "cfg = HookedTransformerConfig(\n",
    "    n_layers = n_layers,\n",
    "    d_model = 512,\n",
    "    d_head = 64,\n",
    "    n_heads = n_heads,\n",
    "    d_mlp = 2048,\n",
    "    d_vocab = 32,\n",
    "    n_ctx = 1023,\n",
    "    act_fn=\"gelu\",\n",
    "    normalization_type=\"LNPre\"\n",
    ")\n",
    "model = HookedTransformer(cfg)\n",
    "model_name = f\"tf_lens_{n_layers}\"\n",
    "model.load_state_dict(torch.load(f'{MODEL_DIR}{model_name}.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer = 12\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    min_val: int\n",
    "    max_val: int\n",
    "    custom_function: callable\n",
    "    linear_probe_name: str\n",
    "    num_rows: int = 8\n",
    "    num_cols: int = 8\n",
    "    board_seqs_int_file: str = f\"{DATA_DIR}train_board_seqs_int.npy\"\n",
    "    board_seqs_str_file: str = f\"{DATA_DIR}train_board_seqs_str.csv\"\n",
    "    dots_indices_file: str = f\"{DATA_DIR}train_dots_indices.npy\"\n",
    "    skill_file: str = None\n",
    "\n",
    "piece_config = Config(\n",
    "    min_val = -6,\n",
    "    max_val = 6,\n",
    "    custom_function = chess_utils.board_to_piece_state,\n",
    "    linear_probe_name = \"chess_piece_probe\",\n",
    ")\n",
    "\n",
    "color_config = Config(\n",
    "    min_val = -1,\n",
    "    max_val = 1,\n",
    "    custom_function=chess_utils.board_to_piece_color_state,\n",
    "    linear_probe_name=\"chess_color_probe\",\n",
    ")\n",
    "\n",
    "random_config = Config(\n",
    "    min_val = -1,\n",
    "    max_val = 1,\n",
    "    custom_function=chess_utils.board_to_random_state,\n",
    "    linear_probe_name=\"chess_random_probe\",\n",
    ")\n",
    "\n",
    "skill_config = Config(\n",
    "    min_val = -2,\n",
    "    max_val = 20,\n",
    "    custom_function=chess_utils.board_to_skill_state,\n",
    "    linear_probe_name=\"chess_skill_probe\",\n",
    "    num_rows = 1,\n",
    "    num_cols= 1,\n",
    "    board_seqs_int_file = f\"{DATA_DIR}skill_train_board_seqs_int.npy\",\n",
    "    board_seqs_str_file = f\"{DATA_DIR}skill_train_board_seqs_str.csv\",\n",
    "    dots_indices_file = f\"{DATA_DIR}skill_train_dots_indices.npy\",\n",
    "    skill_file = f\"{DATA_DIR}skill_train_skill_level.npy\",\n",
    ")\n",
    "\n",
    "# config = piece_config\n",
    "# config = color_config\n",
    "# config = random_config\n",
    "config = skill_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_seqs_int = torch.tensor(np.load(config.board_seqs_int_file)).long()\n",
    "print(board_seqs_int.shape)\n",
    "dots_indices = torch.tensor(np.load(config.dots_indices_file)).long()\n",
    "# state_stack = torch.tensor(np.load(\"state_stacks_5k.npy\")).long() # TODO: Does loading state stack to memory speed up training?\n",
    "# print(state_stack.shape)\n",
    "print(dots_indices.shape)\n",
    "\n",
    "board_seqs_string = []\n",
    "\n",
    "with open(config.board_seqs_str_file, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        board_seqs_string.append(row[0])\n",
    "print(len(board_seqs_string), len(board_seqs_string[0]))\n",
    "# print(board_seqs_string[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(board_seqs_string[0])\n",
    "# custom_function = chess_utils.board_to_piece_state\n",
    "custom_function = config.custom_function\n",
    "skill_stack = None\n",
    "test_skill = None\n",
    "\n",
    "if config.skill_file is not None:\n",
    "    skill_stack = torch.tensor(np.load(config.skill_file)).long()\n",
    "    # skill_stack = (skill_stack >= 10).long() # TODO: Remove this line, used for testing with cross entropy loss\n",
    "    print(skill_stack.unique())\n",
    "    print(skill_stack.shape)\n",
    "    skill_stack = skill_stack.to(dtype=torch.float32)\n",
    "    test_skill = skill_stack[0]\n",
    "\n",
    "    mean = skill_stack.mean()\n",
    "    std = skill_stack.std()\n",
    "\n",
    "    # Normalize the target values\n",
    "    skill_stack = (skill_stack - mean) / std\n",
    "\n",
    "    print(skill_stack.unique())\n",
    "\n",
    "\n",
    "state_stack = torch.tensor(chess_utils.create_state_stack(board_seqs_string[0], custom_function, test_skill)).long()\n",
    "print(state_stack.shape)\n",
    "\n",
    "state_stacks = chess_utils.create_state_stacks(board_seqs_string[:50], custom_function, skill_stack)\n",
    "print(state_stacks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "max_lr = 2e-4\n",
    "wd = 0.01\n",
    "pos_start = 30 # indexes into white_moves_indices or dot_indices\n",
    "# pos_end = model.cfg.n_ctx - 5\n",
    "# input_length = 680\n",
    "# pos_end = input_length - 0\n",
    "# length = pos_end - pos_start\n",
    "one_hot_range = config.max_val - config.min_val + 1\n",
    "num_epochs = 2\n",
    "num_games = 30000\n",
    "x = 0\n",
    "y = 2\n",
    "# The first mode is blank or not, the second mode is next or prev GIVEN that it is not blank\n",
    "modes = 1\n",
    "# alternating = torch.tensor([1 if i%2 == 0 else -1 for i in range(length)], device=device)\n",
    "\n",
    "print((state_stacks[:, 1, 170, :, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 3e-4\n",
    "min_lr = max_lr / 10\n",
    "max_iters = num_games * num_epochs\n",
    "decay_lr = True\n",
    "games_skill = None\n",
    "\n",
    "mse_loss_function = MSELoss()\n",
    "mae_loss_function = L1Loss()\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "\n",
    "def get_lr(current_iter: int, max_iters: int, max_lr: float, min_lr: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the learning rate using linear decay.\n",
    "\n",
    "    Args:\n",
    "    - current_iter (int): The current iteration.\n",
    "    - max_iters (int): The total number of iterations for decay.\n",
    "    - lr (float): The initial learning rate.\n",
    "    - min_lr (float): The minimum learning rate after decay.\n",
    "\n",
    "    Returns:\n",
    "    - float: The calculated learning rate.\n",
    "    \"\"\"\n",
    "    # Ensure current_iter does not exceed max_iters\n",
    "    current_iter = min(current_iter, max_iters)\n",
    "\n",
    "    # Calculate the linearly decayed learning rate\n",
    "    decayed_lr = max_lr - (max_lr - min_lr) * (current_iter / max_iters)\n",
    "\n",
    "    return decayed_lr\n",
    "\n",
    "def train_linear_probe(layer: int):\n",
    "    linear_probe_name = f\"{MODEL_DIR}{model_name}_{config.linear_probe_name}_layer_{layer}.pth\"\n",
    "    linear_probe = torch.randn(\n",
    "        modes, model.cfg.d_model, config.num_rows, config.num_cols, requires_grad=False, device=device\n",
    "    )/np.sqrt(model.cfg.d_model)\n",
    "    linear_probe.requires_grad = True\n",
    "    print(linear_probe.shape)\n",
    "    lr = max_lr\n",
    "    optimiser = torch.optim.AdamW([linear_probe], lr=lr, betas=(0.9, 0.99), weight_decay=wd)\n",
    "\n",
    "    print(dots_indices.shape)\n",
    "\n",
    "    # print(dots_indices.shape)\n",
    "\n",
    "    wandb_logging = False\n",
    "    wandb_project = \"chess_linear_probes\"\n",
    "    wandb_run_name = f\"{config.linear_probe_name}_{model_name}_layer_{layer}\"\n",
    "\n",
    "    if wandb_logging:\n",
    "        import wandb\n",
    "        logging_dict = {\"linear_probe_name\": config.linear_probe_name, \"model_name\": model_name, \"layer\": layer,\n",
    "                        \"batch_size\": batch_size, \"max_lr\": max_lr, \"wd\": wd, \"pos_start\": pos_start,\n",
    "                        \"num_epochs\": num_epochs, \"num_games\": num_games, \"x\": x, \"y\": y, \"modes\": modes,\n",
    "                        \"one_hot_range\": one_hot_range, \"wandb_project\": wandb_project, \"wandb_run_name\": wandb_run_name}\n",
    "        wandb.init(project=wandb_project, name=wandb_run_name, config=config)\n",
    "\n",
    "\n",
    "    current_iter = 0\n",
    "    loss = 0\n",
    "    acc_blank = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        full_train_indices = torch.randperm(num_games)\n",
    "        for i in tqdm(range(0, num_games, batch_size)):\n",
    "\n",
    "            lr = get_lr(current_iter, max_iters, max_lr, min_lr) if decay_lr else lr\n",
    "            for param_group in optimiser.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            \n",
    "            indices = full_train_indices[i:i+batch_size]\n",
    "            list_of_indices = indices.tolist() # For indexing into the board_seqs_string list of strings\n",
    "            # print(list_of_indices)\n",
    "            games_int = board_seqs_int[indices]\n",
    "            games_int = games_int[:, :]\n",
    "            # print(games_int.shape)\n",
    "            games_str = [board_seqs_string[idx] for idx in list_of_indices]\n",
    "            games_str = [s[:] for s in games_str]\n",
    "            games_dots = dots_indices[indices]\n",
    "            games_dots = games_dots[:, pos_start:]\n",
    "            # print(games_dots.shape)\n",
    "\n",
    "            if config.skill_file is not None:\n",
    "                games_skill = skill_stack[indices]\n",
    "                # print(\"GAMES SKILL\", games_skill)\n",
    "                # print(games_skill.shape)\n",
    "            else:\n",
    "                games_skill = None\n",
    "\n",
    "            state_stack = chess_utils.create_state_stacks(games_str, custom_function, games_skill)\n",
    "            # print(\"STATE STACK\", state_stack)\n",
    "            # state_stack = state_stack[:, pos_start:pos_end, :, :]\n",
    "            # print(\"Shape before indexing state stack:\", state_stack.shape)\n",
    "            # Initialize a list to hold the indexed state stacks\n",
    "            indexed_state_stacks = []\n",
    "\n",
    "            for batch_idx in range(batch_size): # TODO FIX Batching\n",
    "                # Get the indices for the current batch\n",
    "                dots_indices_for_batch = games_dots[batch_idx]\n",
    "\n",
    "                # Index the state_stack for the current batch\n",
    "                indexed_state_stack = state_stack[:, batch_idx, dots_indices_for_batch, :, :]\n",
    "\n",
    "                # Append the result to the list\n",
    "                indexed_state_stacks.append(indexed_state_stack)\n",
    "\n",
    "            # Stack the indexed state stacks along the first dimension\n",
    "            # This results in a tensor of shape [2, 61, 8, 8] (assuming all batches have 61 indices)\n",
    "            # print(\"Length of indexed state stacks\", len(indexed_state_stacks))\n",
    "            state_stack = torch.stack(indexed_state_stacks).to(device)\n",
    "            state_stack = state_stack.to(dtype=torch.float32)\n",
    "            \n",
    "            # Use einops to rearrange the dimensions after stacking\n",
    "            state_stack = einops.rearrange(state_stack, 'batch modes pos row col -> modes batch pos row col')\n",
    "\n",
    "            # print(\"after indexing state stack shape\", state_stack.shape)\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                _, cache = model.run_with_cache(games_int.to(device)[:, :-1], return_type=None)\n",
    "                resid_post = cache[\"resid_post\", layer][:, :]\n",
    "            # Initialize a list to hold the indexed state stacks\n",
    "            indexed_resid_posts = []\n",
    "\n",
    "            for batch_idx in range(games_dots.size(0)):\n",
    "                # Get the indices for the current batch\n",
    "                dots_indices_for_batch = games_dots[batch_idx]\n",
    "\n",
    "                # Index the state_stack for the current batch\n",
    "                indexed_resid_post = resid_post[batch_idx, dots_indices_for_batch]\n",
    "\n",
    "                # Append the result to the list\n",
    "                indexed_resid_posts.append(indexed_resid_post)\n",
    "\n",
    "            # Stack the indexed state stacks along the first dimension\n",
    "            # This results in a tensor of shape [2, 61, 8, 8] (assuming all batches have 61 indices)\n",
    "            resid_post = torch.stack(indexed_resid_posts)\n",
    "            # print(\"Resid post\", resid_post.shape)\n",
    "            probe_out = einsum(\n",
    "                \"batch pos d_model, modes d_model rows cols -> modes batch pos rows cols\",\n",
    "                resid_post,\n",
    "                linear_probe,\n",
    "            )\n",
    "            # print(probe_out.shape)\n",
    "\n",
    "            assert probe_out.shape == state_stack.shape\n",
    "\n",
    "            # acc_blank = (probe_out[0].argmax(-1) == state_stack_one_hot[0].argmax(-1)).float().mean()\n",
    "            # acc_color = ((probe_out[1].argmax(-1) == state_stack_one_hot[1].argmax(-1)) * state_stack_one_hot[1].sum(-1)).float().sum()/(state_stack_one_hot[1]).float().sum()\n",
    "\n",
    "            \n",
    "\n",
    "            # loss_even = -probe_correct_log_probs[0, 0::2].mean(0).sum() # note that \"even\" means odd in the game framing, since we offset by 5 moves lol\n",
    "            # loss_odd = -probe_correct_log_probs[1, 1::2].mean(0).sum()\n",
    "            # print(probe_out.shape, state_stack.shape)\n",
    "            # print(probe_out[0][0][0][0][0])\n",
    "            # print(state_stack[0][0][0][0][0])\n",
    "            mse_loss = mse_loss_function(probe_out, state_stack)\n",
    "            mae_loss = mae_loss_function(probe_out, state_stack)\n",
    "            \n",
    "            mae_loss_denormalized = mae_loss * std\n",
    "\n",
    "            # print(probe_out.shape, probe_out.dtype)\n",
    "            # print(state_stack.shape, state_stack.dtype)\n",
    "\n",
    "            # loss_all = probe_out.sum()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"epoch {epoch}, batch {i}, mae loss {mae_loss.item()}, mae denorm loss {mae_loss_denormalized.item()}, mse loss {mse_loss.item()}, lr {lr}\")\n",
    "                if wandb_logging:\n",
    "                    wandb.log({\"acc\": mae_loss.item(),\n",
    "                            \"loss\": mse_loss.item(),\n",
    "                            \"mae_denorm_loss\": mae_loss_denormalized.item(),\n",
    "                            \"lr\": lr,\n",
    "                            \"epoch\": epoch,\n",
    "                            \"iter\": current_iter})\n",
    "\n",
    "            # if i % 1000 == 0:\n",
    "            #     print(f\"epoch {epoch}, batch {i}, acc_blank {acc_blank}, acc_color {acc_color}, loss_even {loss_even}, loss_odd {loss_odd}, loss_all {loss_all}\")\n",
    "            \n",
    "            # loss = loss_even + loss_odd + loss_all\n",
    "            loss = mse_loss\n",
    "            loss.backward() # it's important to do a single backward pass for mysterious PyTorch reasons, so we add up the losses - it's per mode and per square.\n",
    "        \n",
    "\n",
    "            optimiser.step()\n",
    "            optimiser.zero_grad()\n",
    "            current_iter += batch_size\n",
    "\n",
    "    checkpoint = {\n",
    "        \"linear_probe\": linear_probe,\n",
    "        \"layer\": layer,\n",
    "        \"config_name\": config.linear_probe_name,\n",
    "        \"final_loss\": loss,\n",
    "        \"model_name\": model_name,\n",
    "        \"iters\": current_iter,\n",
    "        \"epochs\": epoch,\n",
    "        \"acc\": acc_blank,\n",
    "    }\n",
    "    torch.save(checkpoint, linear_probe_name)\n",
    "\n",
    "# for i in range(0, n_layers+1, 2):\n",
    "#     train_linear_probe(i)\n",
    "train_linear_probe(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
