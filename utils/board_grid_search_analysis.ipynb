{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reference   \n",
    "\n",
    " # info_dict = {\n",
    "    #     \"game_id\": unique_game_id,\n",
    "    #     \"transcript\": game_state,\n",
    "    #     \"result\": result,\n",
    "    #     \"player_one\": player_one_title,\n",
    "    #     \"player_two\": player_two_title,\n",
    "    #     \"player_one_score\": player_one_score,\n",
    "    #     \"player_two_score\": player_two_score,\n",
    "    #     \"player_one_illegal_moves\": player_one_illegal_moves,\n",
    "    #     \"player_two_illegal_moves\": player_two_illegal_moves,\n",
    "    #     \"player_one_resignation\": player_one_resignation,\n",
    "    #     \"player_two_resignation\": player_two_resignation,\n",
    "    #     \"game_title\": f\"{player_one_title} vs. {player_two_title}\",\n",
    "    #     \"number_of_moves\": board.fullmove_number,\n",
    "    #     \"time_taken\": total_time,\n",
    "    # }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GRID_SEARCH_DIR = \"intervention_logs\"\n",
    "\n",
    "for file in os.listdir(GRID_SEARCH_DIR):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "GRID_SEARCH_DIR = \"intervention_logs\"\n",
    "\n",
    "def extract_info_from_filename(filename: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts information from the filename using regular expressions.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): The filename from which to extract the information.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the extracted information.\n",
    "    \"\"\"\n",
    "    # Define the regex pattern to extract the needed information\n",
    "    pattern = r\"sampling=both_intervention_type=(?P<intervention_type>\\w+)_first_layer=(?P<first_layer>\\d+)_last_layer=(?P<last_layer>\\d+)_p=(?P<p>\\d+\\.\\d+)_b=(?P<b>\\d+\\.\\d+)_scales=\"\n",
    "    \n",
    "    # Use the regex search function to find matches\n",
    "    match = re.search(pattern, filename)\n",
    "\n",
    "    # If a match is found, extract the information\n",
    "    if match:\n",
    "        info = match.groupdict()\n",
    "        # Convert numeric values from strings to their appropriate types\n",
    "        info['first_layer'] = int(info['first_layer'])\n",
    "        info['last_layer'] = int(info['last_layer'])\n",
    "        info['p'] = float(info['p'])\n",
    "        info['b'] = float(info['b'])\n",
    "        return info\n",
    "    else:\n",
    "        return {\"error\": \"No match found\"}\n",
    "\n",
    "# List all CSV files\n",
    "json_files = [f for f in os.listdir(GRID_SEARCH_DIR) if f.endswith('.json')]\n",
    "\n",
    "# Dictionary to hold file names and their average scores\n",
    "average_scores_dict = {}\n",
    "\n",
    "for file in json_files:\n",
    "    file_info = extract_info_from_filename(file)\n",
    "    if \"error\" in file_info:\n",
    "        continue\n",
    "    # if file_info[\"first_layer\"] != file_info[\"last_layer\"]:\n",
    "    #     continue\n",
    "\n",
    "    with open(f\"{GRID_SEARCH_DIR}/{file}\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    if \"possible_sampled_moves\" not in data:\n",
    "        continue\n",
    "    average_scores_dict[file] = {}\n",
    "    average_scores_dict[file][\"possible_sampled_moves\"] = data[\"possible_sampled_moves\"]\n",
    "    for key in data:\n",
    "        try:\n",
    "            # Try to convert the key to float\n",
    "            float_key = float(key)\n",
    "            # If conversion is successful, add the key to the dictionary\n",
    "            average_scores_dict[file][key] = data[key]\n",
    "        except ValueError:\n",
    "            # If conversion fails, the key is not a float\n",
    "            pass\n",
    "\n",
    "sampled_ratio_list = []\n",
    "for file in average_scores_dict:\n",
    "    max_possible = average_scores_dict[file][\"possible_sampled_moves\"]\n",
    "    for scale in average_scores_dict[file]:\n",
    "        if scale == \"possible_sampled_moves\":\n",
    "            continue\n",
    "        legal_sampled = average_scores_dict[file][scale][\"mod_board_sampled_legal_total\"]\n",
    "        sampled_ratio = legal_sampled / max_possible\n",
    "        average_scores_dict[file][scale][\"sampled_ratio\"] = sampled_ratio\n",
    "        sampled_ratio_list.append((file, scale, sampled_ratio))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sort the files by average score\n",
    "sorted_sampled_ratio_list = sorted(sampled_ratio_list, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Print sorted files and their scores\n",
    "for file, scale, score in sorted_sampled_ratio_list:\n",
    "    # if \"gradient\" not in file:\n",
    "    #     continue\n",
    "    # if scale != \"3.0\":\n",
    "    #     continue\n",
    "    print(f\"{file}, {scale}, {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "GRID_SEARCH_DIR = \"intervention_logs\"\n",
    "\n",
    "def extract_info_from_filename(filename: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts information from the filename using regular expressions.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): The filename from which to extract the information.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the extracted information.\n",
    "    \"\"\"\n",
    "    # Define the regex pattern to extract the needed information\n",
    "    pattern = r\"sampling=both_n_layers=8_intervention_type=(?P<intervention_type>\\w+)_first_layer=(?P<first_layer>\\d+)_last_layer=(?P<last_layer>\\d+)_p=(?P<p>\\d+\\.\\d+)_b=(?P<b>\\d+\\.\\d+)_iters=(?P<iters>\\d+)_scales=\"\n",
    "    \n",
    "    # Use the regex search function to find matches\n",
    "    match = re.search(pattern, filename)\n",
    "\n",
    "    # If a match is found, extract the information\n",
    "    if match:\n",
    "        info = match.groupdict()\n",
    "        # Convert numeric values from strings to their appropriate types\n",
    "        info['first_layer'] = int(info['first_layer'])\n",
    "        info['last_layer'] = int(info['last_layer'])\n",
    "        info['p'] = float(info['p'])\n",
    "        info['b'] = float(info['b'])\n",
    "        return info\n",
    "    else:\n",
    "        return {\"error\": \"No match found\"}\n",
    "\n",
    "# List all CSV files\n",
    "json_files = [f for f in os.listdir(GRID_SEARCH_DIR) if f.endswith('.json')]\n",
    "\n",
    "# Dictionary to hold file names and their average scores\n",
    "average_scores_dict = {}\n",
    "\n",
    "for file in json_files:\n",
    "    file_info = extract_info_from_filename(file)\n",
    "    if \"error\" in file_info:\n",
    "        continue\n",
    "    # if file_info[\"first_layer\"] != file_info[\"last_layer\"]:\n",
    "    #     continue\n",
    "\n",
    "    with open(f\"{GRID_SEARCH_DIR}/{file}\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    if \"possible_sampled_moves\" not in data:\n",
    "        continue\n",
    "    average_scores_dict[file] = {}\n",
    "    average_scores_dict[file][\"possible_sampled_moves\"] = data[\"possible_sampled_moves\"]\n",
    "    for key in data:\n",
    "        try:\n",
    "            # Try to convert the key to float\n",
    "            float_key = float(key)\n",
    "            # If conversion is successful, add the key to the dictionary\n",
    "            average_scores_dict[file][key] = data[key]\n",
    "        except ValueError:\n",
    "            # If conversion fails, the key is not a float\n",
    "            pass\n",
    "\n",
    "sampled_ratio_list = []\n",
    "for file in average_scores_dict:\n",
    "    max_possible = average_scores_dict[file][\"possible_sampled_moves\"]\n",
    "    for scale in average_scores_dict[file]:\n",
    "        if scale == \"possible_sampled_moves\":\n",
    "            continue\n",
    "        legal_sampled = average_scores_dict[file][scale][\"mod_board_sampled_legal_total\"]\n",
    "        sampled_ratio = legal_sampled / max_possible\n",
    "        average_scores_dict[file][scale][\"sampled_ratio\"] = sampled_ratio\n",
    "        sampled_ratio_list.append((file, scale, sampled_ratio))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sort the files by average score\n",
    "sorted_sampled_ratio_list = sorted(sampled_ratio_list, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Print sorted files and their scores\n",
    "for file, scale, score in sorted_sampled_ratio_list:\n",
    "    # if \"gradient\" not in file:\n",
    "    #     continue\n",
    "    # if scale != \"3.0\":\n",
    "    #     continue\n",
    "    print(f\"{file}, {scale}, {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import sem, t\n",
    "\n",
    "def compute_average_score_and_confidence_interval(file_path: str, player: str = \"player_one\", confidence=0.95) -> dict:\n",
    "    file_path = os.path.join(GRID_SEARCH_DIR, file_path)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Filter rows where 'Stockfish -1' is in 'game_title'\n",
    "    # df = df[df['game_title'].str.contains(\"Stockfish 0\")]\n",
    "    df = df[~df['game_title'].str.contains(\"Stockfish -1\")]\n",
    "\n",
    "    # df = df[df['player_one_failed_to_find_legal_move'] == False]\n",
    "\n",
    "    total_moves = len(df)\n",
    "    successful_moves = df[df[f'{player}_failed_to_find_legal_move'] == False].shape[0]\n",
    "    percentage_successful = (successful_moves / total_moves) * 100\n",
    "\n",
    "    df[f\"{player}_score\"] = pd.to_numeric(df[f\"{player}_score\"], errors=\"coerce\")\n",
    "\n",
    "    # Compute overall average score and confidence interval\n",
    "    scores = df[f\"{player}_score\"].dropna()\n",
    "    if len(scores) > 1:\n",
    "        mean_score = np.mean(scores)\n",
    "        std_err = sem(scores)\n",
    "        h = std_err * t.ppf((1 + confidence) / 2, len(scores) - 1)\n",
    "        result = {\"mean_score\": mean_score, \"confidence_interval\": (mean_score - h, mean_score + h)}\n",
    "    else:\n",
    "        result = {\"mean_score\": scores.iloc[0], \"confidence_interval\": (np.nan, np.nan)}\n",
    "\n",
    "    result[\"percentage_successful\"] = percentage_successful\n",
    "    result[\"total_moves\"] = total_moves\n",
    "\n",
    "    # print(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "    # # Compute average scores and confidence intervals\n",
    "    # results = {}\n",
    "    # for game_title, group in df.groupby(\"game_title\"):\n",
    "    #     scores = group[f\"{player}_score\"].dropna()\n",
    "    #     if len(scores) > 1:\n",
    "    #         mean_score = np.mean(scores)\n",
    "    #         std_err = sem(scores)\n",
    "    #         h = std_err * t.ppf((1 + confidence) / 2, len(scores) - 1)\n",
    "    #         results[game_title] = {\"mean_score\": mean_score, \"confidence_interval\": (mean_score - h, mean_score + h)}\n",
    "    #     else:\n",
    "    #         results[game_title] = {\"mean_score\": scores.iloc[0], \"confidence_interval\": (np.nan, np.nan)}\n",
    "\n",
    "    # print(results)\n",
    "    # return results\n",
    "\n",
    "# List all CSV files\n",
    "json_files = [f for f in os.listdir(GRID_SEARCH_DIR) if f.endswith('.csv')]\n",
    "\n",
    "# Dictionary to hold file names and their average scores\n",
    "results_dict = {}\n",
    "average_scores_dict = {}\n",
    "\n",
    "for file in json_files:\n",
    "    try:\n",
    "        # if \"10_random_moves\" not in file:\n",
    "        #     continue\n",
    "        # if \"0_1_coefficient\" in file:\n",
    "        #     continue\n",
    "        if \"levels_14\" in file or \"levels_15\" in file or \"levels_04\" in file:\n",
    "            continue\n",
    "        if \"200k\" in file:\n",
    "            continue\n",
    "        if \"pos_start_32\" in file:\n",
    "            continue\n",
    "        if \"20000_moves\" in file:\n",
    "            continue\n",
    "        # if \"layer_8\" in file:\n",
    "        #     continue\n",
    "        # if \"8layers\" not in file and \"layers_8\" not in file:\n",
    "        if \"8layers\" in file or \"layers_8\" in file:\n",
    "            continue\n",
    "        result = compute_average_score_and_confidence_interval(file)\n",
    "        average_scores_dict[file] = result[\"mean_score\"]\n",
    "        results_dict[file] = result\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "# Sort the files by average score\n",
    "sorted_files = sorted(average_scores_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print sorted files and their scores\n",
    "for file, score in sorted_files:\n",
    "    if \"10_random_moves\" not in file:\n",
    "        continue\n",
    "    confidence_interval = results_dict[file][\"confidence_interval\"]\n",
    "    total_moves = results_dict[file][\"total_moves\"]\n",
    "    percentage_successful = results_dict[file][\"percentage_successful\"]\n",
    "    # if file.startswith(\"lichess_train\"):\n",
    "    #     file = file.replace(\"lichess_train\", \"lichess_000k_bins_train\")\n",
    "    # if total_moves <= 100:\n",
    "    #     continue\n",
    "\n",
    "    print(f\"{file}: {score}, {total_moves}, {percentage_successful}, {confidence_interval}\")\n",
    "\n",
    "print(\"\\n\\nBegin 0 random moves\\n\\n\")\n",
    "# Print sorted files and their scores\n",
    "for file, score in sorted_files:\n",
    "    if \"_0_random_moves\" not in file:\n",
    "        continue\n",
    "    confidence_interval = results_dict[file][\"confidence_interval\"]\n",
    "    total_moves = results_dict[file][\"total_moves\"]\n",
    "    percentage_successful = results_dict[file][\"percentage_successful\"]\n",
    "    # if file.startswith(\"lichess_train\"):\n",
    "    #     file = file.replace(\"lichess_train\", \"lichess_000k_bins_train\")\n",
    "    # if total_moves <= 100:\n",
    "    #     continue\n",
    "\n",
    "    print(f\"{file}: {score}, {total_moves}, {percentage_successful}, {confidence_interval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "def modify_filename(filename: str, variable: str) -> Tuple[str, str]:\n",
    "    # Use regex to replace the variable value with 'xx'\n",
    "    pattern = fr\"({variable}_)(\\d+)\"\n",
    "    # pattern = fr\"(\\d+)(_{variable})\"\n",
    "\n",
    "    original_value = re.search(pattern, filename)\n",
    "    if original_value:\n",
    "        modified_filename = re.sub(pattern, fr\"\\1xx\", filename)\n",
    "        return modified_filename, original_value.group(2)\n",
    "    return filename, \"\"\n",
    "\n",
    "def group_by_single_variable_change(sorted_files: List[Tuple[str, any]], variable: str) -> Dict[str, List[Tuple[str, str, any]]]:\n",
    "    grouped_files = defaultdict(list)\n",
    "    for filename, *other_data in sorted_files:\n",
    "        modified_filename, original_value = modify_filename(filename, variable)\n",
    "        grouped_files[modified_filename].append((filename, original_value, *other_data))\n",
    "    return grouped_files\n",
    "\n",
    "# Example usage:\n",
    "# sorted_files = [\n",
    "#     # Your list of tuples here. Each tuple should at least have a filename\n",
    "# ]\n",
    "variable = \"random_moves\"  # Change this to the variable you want to focus on\n",
    "variable = \"pt\"\n",
    "# variable = \"pos_start\"\n",
    "grouped = group_by_single_variable_change(sorted_files, variable)\n",
    "\n",
    "for modified_filename, file_info in grouped.items():\n",
    "    if len(file_info) > 0:\n",
    "        if \"200k\" not in modified_filename:\n",
    "            continue\n",
    "        print(f\"{modified_filename}:\")\n",
    "        for info in file_info:\n",
    "            original_filename, value, *additional_data = info\n",
    "            score = additional_data[0] if additional_data else None  # Assuming the score is the first item in additional_data\n",
    "            print(f\"  Original: {original_filename}, Value: {value}, Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import sem, t\n",
    "\n",
    "def compute_percentage_of_successful_moves(file_path: str, player: str = \"player_one\", confidence=0.9) -> dict:\n",
    "    \"\"\"\n",
    "    Computes the percentage of successful moves and confidence interval for a given player.\n",
    "\n",
    "    :param file_path: Path to the CSV file containing game data.\n",
    "    :param player: The player for whom to compute the statistics (default is 'player_one').\n",
    "    :param confidence: Confidence level for the interval calculation (default is 0.95).\n",
    "    :return: A dictionary with the percentage of successful moves and the confidence interval.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(GRID_SEARCH_DIR, file_path)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Filter rows where 'Stockfish 0' is in 'game_title'\n",
    "    # df = df[df['game_title'].str.contains(\"Stockfish 0\")]\n",
    "\n",
    "    # Calculate the percentage of successful moves\n",
    "    total_moves = len(df)\n",
    "    successful_moves = df[df[f'{player}_failed_to_find_legal_move'] == False].shape[0]\n",
    "    percentage_successful = (successful_moves / total_moves) * 100\n",
    "\n",
    "    # Compute confidence interval for the proportion\n",
    "    proportion = successful_moves / total_moves\n",
    "    std_err = np.sqrt(proportion * (1 - proportion) / total_moves)\n",
    "    h = std_err * t.ppf((1 + confidence) / 2, total_moves - 1)\n",
    "    confidence_interval = (proportion - h, proportion + h)\n",
    "\n",
    "    return {\n",
    "        \"percentage_successful\": percentage_successful,\n",
    "        \"confidence_interval\": (confidence_interval[0] * 100, confidence_interval[1] * 100)\n",
    "    }\n",
    "\n",
    "    # # Compute average scores and confidence intervals\n",
    "    # results = {}\n",
    "    # for game_title, group in df.groupby(\"game_title\"):\n",
    "    #     scores = group[f\"{player}_score\"].dropna()\n",
    "    #     if len(scores) > 1:\n",
    "    #         mean_score = np.mean(scores)\n",
    "    #         std_err = sem(scores)\n",
    "    #         h = std_err * t.ppf((1 + confidence) / 2, len(scores) - 1)\n",
    "    #         results[game_title] = {\"mean_score\": mean_score, \"confidence_interval\": (mean_score - h, mean_score + h)}\n",
    "    #     else:\n",
    "    #         results[game_title] = {\"mean_score\": scores.iloc[0], \"confidence_interval\": (np.nan, np.nan)}\n",
    "\n",
    "    # print(results)\n",
    "    # return results\n",
    "\n",
    "# List all CSV files\n",
    "json_files = [f for f in os.listdir(GRID_SEARCH_DIR) if f.endswith('.csv')]\n",
    "\n",
    "# Dictionary to hold file names and their average scores\n",
    "average_scores_dict = {}\n",
    "confidence_interval_dict = {}\n",
    "\n",
    "for file in json_files:\n",
    "    try:\n",
    "        if \"10_random_moves\" in file:\n",
    "            continue\n",
    "        # if \"0_1_coefficient\" in file:\n",
    "        #     continue\n",
    "        if \"pos_start_32\" in file:\n",
    "            continue\n",
    "        result = compute_percentage_of_successful_moves(file)\n",
    "        confidence_interval_dict[file] = result[\"confidence_interval\"]\n",
    "        average_scores_dict[file] = result[\"percentage_successful\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "# Sort the files by average score\n",
    "sorted_files = sorted(average_scores_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print sorted files and their scores\n",
    "for file, score in sorted_files:\n",
    "    confidence_interval = confidence_interval_dict[file]\n",
    "    if file.startswith(\"lichess_train\"):\n",
    "        file = file.replace(\"lichess_train\", \"lichess_000k_bins_train\")\n",
    "\n",
    "    print(f\"{file}: {score}, {confidence_interval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def graph_player_gpt_score(player: str, df: pd.DataFrame) -> None:\n",
    "    if player != \"player_one\" and player != \"player_two\":\n",
    "        raise ValueError(\"player must be either 'player_one' or 'player_two'\")\n",
    "    \n",
    "    # Convert the player_one_score column to numeric type (if it's not already)\n",
    "    df[f\"{player}_score\"] = pd.to_numeric(df[f\"{player}_score\"], errors=\"coerce\")\n",
    "    print(df[f\"{player}_score\"].unique())\n",
    "\n",
    "    # Compute average score of player_one grouped by game_title\n",
    "    average_scores = df.groupby(\"game_title\")[f\"{player}_score\"].mean()\n",
    "\n",
    "    # Display the result\n",
    "    print(average_scores)\n",
    "\n",
    "    average_scores.index = average_scores.index.str.split(' vs. ').str[1].str.strip()\n",
    "\n",
    "    average_scores.plot(kind=\"bar\", figsize=(10, 5))\n",
    "    plt.title(f\"Average gpt-3.5-turbo-instruct Win Rate by Opponent Skill over 15 rounds\")\n",
    "    plt.ylabel(\"Average Score\")\n",
    "    plt.xlabel(\"Stockfish Level (time = 0.1 seconds per move)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(\"gpt-3.5-turbo-instruct-win-rate.png\")\n",
    "\n",
    "filename = \"logs/ckpt_16_pt_vs_stockfish_sweep.csv\"\n",
    "filename = \"logs/ckpt_8_pt_vs_stockfish_sweep.csv\"\n",
    "# filename = \"logs/2325_lichess_ckpt_pt_vs_stockfish_sweep.csv\"\n",
    "# filename = \"logs/ckpt_synthetic_split_no_opt_pt_vs_stockfish_sweep.csv\"\n",
    "filename = \"logs/lichess_16_ckpt_pt_vs_stockfish_sweep.csv\"\n",
    "# filename = \"logs/lichess_8layers_ckpt_no_optimizer_pt_vs_stockfish_sweep.csv\"\n",
    "# filename = \"logs/lichess_stockfish_mix_8layers_ckpt_no_optimizer_pt_vs_stockfish_sweep.csv\"\n",
    "# filename = \"logs/lichess_8layers_results_ckpt_no_optimizer_pt_vs_stockfish_sweep.csv\"\n",
    "# filename = \"logs/12_25_01_coeff_pt_vs_stockfish_sweep.csv\"\n",
    "# filename = \"logs/no_activation_pt_vs_stockfish_sweep copy.csv\"\n",
    "# filename = \"logs/lichess_train_layer_12_pos_start_25_activations_pt_vs_stockfish_sweep.csv\"\n",
    "# filename = \"logs/lichess_train_layer_12_pos_start_25_activations_pt_10_random_moves_vs_stockfish_sweep.csv\"\n",
    "# filename = \"logs/no_activation_pt_10_random_moves_vs_stockfish_sweep.csv\"\n",
    "# filename = \"logs/lichess_200k_bins_16layers_ckpt_no_optimizer_pt_vs_stockfish_sweep.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "print(len(df))\n",
    "\n",
    "graph_player_gpt_score(\"player_one\", df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def graph_player_gpt_scores(player: str, dfs: list[pd.DataFrame], labels: list[str]) -> None:\n",
    "    if player != \"player_one\" and player != \"player_two\":\n",
    "        raise ValueError(\"player must be either 'player_one' or 'player_two'\")\n",
    "    \n",
    "    avg_scores_list = []\n",
    "\n",
    "    for df in dfs:\n",
    "        \n",
    "        # Convert the player_score column to numeric type (if it's not already)\n",
    "        df[f\"modified_{player}_score\"] = pd.to_numeric(df[f\"modified_{player}_score\"], errors=\"coerce\")\n",
    "\n",
    "        # Compute average score of player grouped by game_title\n",
    "        avg_scores = df.groupby(\"game_title\")[f\"modified_{player}_score\"].mean()\n",
    "        avg_scores_list.append(avg_scores)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    # for i, avg_scores in enumerate(avg_scores_list):\n",
    "    #     avg_scores.index = avg_scores.index.str.split(' vs. ').str[1].str.strip()\n",
    "    #     avg_scores.plot(kind=\"bar\", position=i, label=labels[i])\n",
    "\n",
    "    for df, label in zip(dfs, labels):\n",
    "        df = df[df['player_two'] != 'Stockfish 10'].copy()\n",
    "        # Convert the player_score column to numeric type (if it's not already)\n",
    "        df[f\"modified_{player}_score\"] = pd.to_numeric(df[f\"modified_{player}_score\"], errors=\"coerce\")\n",
    "\n",
    "        # Compute average score of player grouped by game_title\n",
    "        avg_scores = df.groupby(\"game_title\")[f\"modified_{player}_score\"].mean()\n",
    "\n",
    "        # Clean up the index for better labeling\n",
    "        avg_scores.index = avg_scores.index.str.split(' vs. ').str[1].str.strip()\n",
    "\n",
    "        # Plotting\n",
    "        plt.plot(avg_scores, label=label, marker='o')  # Line chart with markers\n",
    "\n",
    "\n",
    "    plt.title(f\"Average Chess-GPT Win Rate by Opponent Skill over 100 rounds\")\n",
    "    plt.ylabel(\"Average Win Rate\")\n",
    "    plt.xlabel(\"Stockfish Level (time = 0.1 seconds per move)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"llm-win-rate.png\")\n",
    "    # plt.show()  # Uncomment this if you want to display the plot\n",
    "\n",
    "# Example usage\n",
    "filenames = [\n",
    "\"logs/ckpt_16_pt_vs_stockfish_sweep.csv\",\n",
    "\"logs/ckpt_8_pt_vs_stockfish_sweep.csv\",\n",
    "# \"logs/ckpt_synthetic_split_no_opt_pt_vs_stockfish_sweep.csv\",\n",
    "\"logs/lichess_16_ckpt_pt_vs_stockfish_sweep.csv\",\n",
    "\"logs/lichess_8layers_ckpt_no_optimizer_pt_vs_stockfish_sweep.csv\",\n",
    "\"logs/lichess_stockfish_mix_8layers_ckpt_no_optimizer_pt_vs_stockfish_sweep.csv\",\n",
    "# \"logs/lichess_8layers_results_ckpt_no_optimizer_pt_vs_stockfish_sweep.csv\",\n",
    "# \"logs/lichess_8layers_results_ckpt_no_optimizer_pt_vs_stockfish_sweep_1-0.csv\",\n",
    "\"logs/lichess_8layers_gt_18k_ckpt_no_optimizer_pt_vs_stockfish_sweep.csv\"\n",
    "]\n",
    "\n",
    "dfs = [pd.read_csv(filename) for filename in filenames]\n",
    "labels = [\"Stockfish - 16 layers\",\n",
    "        \"Stockfish - 8 layers\",\n",
    "        \"Lichess - 16 layers\",\n",
    "        \"Lichess - 8 Layers\",\n",
    "         \"Lichess / Stockfish Mix - 8 Layers\",\n",
    "        #  \"Lichess Results - 8 Layers\",\n",
    "        #  \"Lichess Results - 8 Layers (1-0)\",\n",
    "         \"Lichess > 1800 ELO - 8 Layers\"]\n",
    "\n",
    "graph_player_gpt_scores(\"player_one\", dfs, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def graph_player_gpt_score(player: str, df: pd.DataFrame) -> None:\n",
    "    if player not in [\"player_one\", \"player_two\"]:\n",
    "        raise ValueError(\"player must be either 'player_one' or 'player_two'\")\n",
    "    \n",
    "    # Convert the score column to numeric type (if it's not already)\n",
    "    df[f\"{player}_score\"] = pd.to_numeric(df[f\"{player}_score\"], errors=\"coerce\")\n",
    "    df[f\"modified_{player}_score\"] = pd.to_numeric(df[f\"modified_{player}_score\"], errors=\"coerce\")\n",
    "\n",
    "    # Categorize each game result into win, loss, or draw\n",
    "    def categorize(score):\n",
    "        if score == 1:\n",
    "            return 'Win'\n",
    "        elif score == 0:\n",
    "            return 'Loss'\n",
    "        else:\n",
    "            return 'Draw'\n",
    "        \n",
    "    df = df[df['player_two'] != 'Stockfish 10'].copy()\n",
    "\n",
    "    df[f\"{player}_result\"] = df[f\"modified_{player}_score\"].apply(categorize)\n",
    "\n",
    "    # Group by game title and result type, then count occurrences\n",
    "    result_counts = df.groupby([\"player_two\", f\"{player}_result\"]).size().unstack().fillna(0)\n",
    "    result_counts = result_counts[['Win', 'Draw', 'Loss']]\n",
    "\n",
    "    # Create a stacked bar chart\n",
    "    result_counts.plot(kind=\"bar\", stacked=True, figsize=(10, 5))\n",
    "\n",
    "    plt.suptitle(f\"50M Chess-GPT vs Stockfish\")\n",
    "    # plt.title(\"Stockfish 0: ELO ~1300, Stockfish 9: ELO ~2700\")\n",
    "    plt.ylabel(\"Number of Games\")\n",
    "    plt.xlabel(\"Stockfish Level (time = 0.1 seconds per move, Stockfish 0: ELO ~1300, Stockfish 9: ELO ~2700)\")\n",
    "    # plt.text(0.5, -0.4, \"Stockfish 0: ELO ~1300, Stockfish 9: ELO ~2700\", ha='center', va='center', transform=plt.gca().transAxes)\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"50M-Chess-GPT-win-rate.png\")\n",
    "\n",
    "# Example usage\n",
    "filename = \"logs/ckpt_16_pt_vs_stockfish_sweep.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "graph_player_gpt_score(\"player_one\", df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def analyze_move_history(df: pd.DataFrame, model: str, player: str) -> None:\n",
    "    if player != \"player_one\" and player != \"player_two\":\n",
    "        raise ValueError(\"player must be either 'player_one' or 'player_two'\")\n",
    "    \n",
    "    model = df[player].unique()[0]\n",
    "\n",
    "    # Filter the DataFrame for games where player title is model\n",
    "    filtered_df = df[df[player] == model]\n",
    "\n",
    "    # Compute total illegal moves and total moves\n",
    "    total_illegal_moves = filtered_df[f\"{player}_illegal_moves\"].sum()\n",
    "    total_legal_moves = filtered_df[f\"{player}_legal_moves\"].sum()\n",
    "    total_moves = filtered_df['total_moves'].sum()\n",
    "\n",
    "    print(f\"\\n{model} Stats\\n\")\n",
    "\n",
    "    # Calculate the ratio\n",
    "    ratio = total_illegal_moves / total_moves\n",
    "    print(f\"total moves: {total_moves}, total illegal moves: {total_illegal_moves}\")\n",
    "    print(f\"total legal moves: {total_legal_moves}\")\n",
    "    # Display the result\n",
    "    print(f\"Ratio of Player One's Illegal Moves to Total Moves: {ratio:.4f}\")\n",
    "    print(f\"Ratio of Player One's Legal Moves to Total Moves: {(total_legal_moves / total_moves):.4f}\")\n",
    "\n",
    "    # Other stats\n",
    "    min_moves = filtered_df['number_of_moves'].min()\n",
    "    max_moves = filtered_df['number_of_moves'].max()\n",
    "    median_moves = filtered_df['number_of_moves'].median()\n",
    "    std_dev_moves = filtered_df['number_of_moves'].std()\n",
    "\n",
    "    \n",
    "    print(f\"Minimum Moves: {min_moves}\")\n",
    "    print(f\"Maximum Moves: {max_moves}\")\n",
    "    print(f\"Median Moves: {median_moves}\")\n",
    "    print(f\"Standard Deviation of Moves: {std_dev_moves:.2f}\")\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "analyze_move_history(df, \"gpt-3.5-turbo-instruct\", \"player_one\")\n",
    "analyze_move_history(df, \"gpt-4\", \"player_one\")\n",
    "analyze_move_history(df, \"gpt-3.5-turbo\", \"player_one\")\n",
    "analyze_move_history(df, \"babbage\", \"player_one\")\n",
    "analyze_move_history(df, \"davinci\", \"player_one\")\n",
    "analyze_move_history(df, \"replicate/meta/llama-2-7b:527827021d8756c7ab79fde0abbfaac885c37a3ed5fe23c7465093f0878d55ef\", \"player_one\")\n",
    "analyze_move_history(df, \"replicate/meta/llama-2-70b:a52e56fee2269a78c9279800ec88898cecb6c8f1df22a6483132bea266648f00\", \"player_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Histogram for distribution of number of moves per game\n",
    "plt.figure(figsize=(10,6))\n",
    "df['number_of_moves'].hist(bins=30, edgecolor='black', color='skyblue')\n",
    "plt.title('Distribution of Number of Moves per Game')\n",
    "plt.xlabel('Number of Moves')\n",
    "plt.ylabel('Number of Games')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by player_two_title and count the occurrences\n",
    "title_counts = df.groupby('game_title').size()\n",
    "\n",
    "print(title_counts)\n",
    "\n",
    "# Filter titles with a count less than 30\n",
    "# titles_less_than_30 = title_counts[title_counts < 30]\n",
    "\n",
    "# # Display the result\n",
    "# print(titles_less_than_30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
