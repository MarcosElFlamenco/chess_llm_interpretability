{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datasets import load_dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/\"\n",
    "prefix = \"lichess_\"\n",
    "\n",
    "input_file = f'{DATA_DIR}lichess_100mb.csv'\n",
    "output_file = f'{DATA_DIR}lichess_100mb_filtered.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(input_file):\n",
    "    dataset_path = \"adamkarvonen/chess_games\"\n",
    "    file_path = \"lichess_100mb.zip\"\n",
    "    dataset = load_dataset(dataset_path, data_files=file_path)\n",
    "    df = pd.DataFrame(dataset['train'])\n",
    "    df.to_csv(input_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_file)\n",
    "\n",
    "for game in df.head()['transcript']:\n",
    "    print(game)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_df = df['transcript'].apply(lambda x: len(x))\n",
    "print(len_df.describe())\n",
    "\n",
    "game_length_in_chars = 365\n",
    "\n",
    "# Data setup. All games must have same length. 50% are >= 690 moves. I will discard all games less than 680, and truncate the rest to 680.\n",
    "filtered_df = df[df['transcript'].apply(lambda x: len(x) >= game_length_in_chars)].copy()\n",
    "filtered_df.loc[:, 'transcript'] = filtered_df['transcript'].apply(lambda x: x[:game_length_in_chars])\n",
    "\n",
    "len_df = filtered_df['transcript'].apply(lambda x: len(x))\n",
    "print(len_df.describe())\n",
    "\n",
    "move_count_df = filtered_df['transcript'].apply(lambda x: len(x.split()))\n",
    "move_count = move_count_df.describe()\n",
    "print(\"move count\", move_count_df.describe())\n",
    "quarter_percentile = move_count['25%']\n",
    "print(\"quarter percentile\", quarter_percentile)\n",
    "\n",
    "# Now I need to filter out games that are too short. I will discard all games less than 25th percentile  moves.\n",
    "filtered_df = filtered_df[filtered_df['transcript'].apply(lambda x: len(x.split()) >= quarter_percentile)]\n",
    "print(filtered_df.describe())\n",
    "print(filtered_df.head())\n",
    "\n",
    "filtered_df.to_csv(output_file, index=False)\n",
    "\n",
    "move_count_df = filtered_df['transcript'].apply(lambda x: len(x.split()))\n",
    "print(move_count_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(filtered_df))\n",
    "print(filtered_df['WhiteElo'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Function to create binned columns and bin index columns\n",
    "def create_binned_columns(df, column_name):\n",
    "    binned_column_name = f'{column_name}Binned'\n",
    "    bin_index_column_name = f'{column_name}BinIndex'\n",
    "    \n",
    "    # Create quantile-based bins\n",
    "    num_bins = 6\n",
    "    # Create quantile-based bins with range labels, dropping duplicates if necessary\n",
    "    df[binned_column_name], bins = pd.qcut(df[column_name], q=num_bins, retbins=True, duplicates='drop')\n",
    "\n",
    "    # Convert bin labels to strings and assign to the column\n",
    "    df[binned_column_name] = df[binned_column_name].apply(lambda x: f'({x.left}, {x.right}]')\n",
    "\n",
    "    # Create bin index column\n",
    "    df[bin_index_column_name] = pd.qcut(df[column_name], q=num_bins, labels=False, duplicates='drop')\n",
    "\n",
    "# Apply the function to both WhiteElo and BlackElo\n",
    "create_binned_columns(filtered_df, 'WhiteElo')\n",
    "create_binned_columns(filtered_df, 'BlackElo')\n",
    "\n",
    "filtered_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 8))\n",
    "\n",
    "# Histogram for WhiteElo\n",
    "axes[0].hist(filtered_df['WhiteElo'], bins=30, color='blue', alpha=0.7)\n",
    "axes[0].set_title('WhiteElo Distribution')\n",
    "axes[0].set_xlabel('WhiteElo')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Bar chart for WhiteEloBinned\n",
    "bin_counts = filtered_df['WhiteEloBinned'].value_counts()\n",
    "axes[1].bar(bin_counts.index.astype(str), bin_counts.values, color='green', alpha=0.7)\n",
    "axes[1].set_title('WhiteElo Binned Distribution')\n",
    "axes[1].set_xlabel('WhiteElo Bins')\n",
    "axes[1].set_ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_df['WhiteEloBinned'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle all rows of the dataset\n",
    "\n",
    "df = pd.read_csv(output_file)\n",
    "df = df.sample(frac=1, random_state=200).reset_index(drop=True)\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "# Split df into a train and test split\n",
    "train = df.sample(frac=0.9, random_state=200)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "\n",
    "# Save the train and test splits to csv\n",
    "train.to_csv(f'{DATA_DIR}{prefix}train.csv', index=False)\n",
    "test.to_csv(f'{DATA_DIR}{prefix}test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
